{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5321935,"sourceType":"datasetVersion","datasetId":3092006}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## 🔹 BABOK + RAG + Gemini tabanlı Business Requirement Chatbot\n# ==============================================================\n## 🎯 Projenin Amacı\n\n# Bu proje, iş analizi sürecinde gereksinimlerin tanımlanması, sınıflandırılması ve önceliklendirilmesini otomatikleştirmek için geliştirilmiştir.\n# Geleneksel olarak saatler süren gereksinim dokümantasyonu artık birkaç saniye içinde otomatik üretilmektedir.\n\n# Sistem:\n# Veri temelli (RAG destekli),\n# Uluslararası standartlara uygun (BABOK),\n# Ölçeklenebilir (ChromaDB + Gemini),\n# Ve kullanıcı dostu (Gradio arayüzü) bir çözümdür.\n\n# Yapay zekâ ve veri tabanı tekniklerini bir araya getirerek, kullanıcıdan alınan proje açıklamasına göre:\n# Gereksinimin Functional (işlevsel) mi yoksa Non-Functional (işlevsel olmayan) mı olduğunu tahmin eder,\n# BABOK (Business Analysis Body of Knowledge) standartlarına göre gereksinim dokümanı üretir,\n# Gereksinimlerin önemini RICE ve WSJF gibi metriklerle önceliklendirir,\n# Kullanıcıya kolay ve interaktif bir arayüz sunar.\n# Kısaca bu chatbot, bir iş analistinin yaptığı “gereksinim çıkarımı, analizi ve dokümantasyon” sürecini kısmen otomatikleştirir.\n# --------------------------------------------------------------\n## 1️⃣ Ortam Değişkeni ve API Anahtarı\n# Bu bölümde gerekli kütüphaneler yüklenir, ortam değişkenleri tanımlanır ve Google Gemini API’si yapılandırılır.\n# Gemini, Google’ın büyük dil modeli (LLM) olup, bu projede gereksinim üretmek ve doğal dil işlemede kullanılır.\n# --------------------------------------------------------------\n!pip install -q chromadb sentence-transformers google-generativeai python-dotenv gradio pandas\n!pip install -q sentence-transformers==2.2.2 transformers==4.41.2 huggingface_hub==0.22.2\nimport re\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nimport pandas as pd\nimport gradio as gr\nfrom dotenv import load_dotenv\nload_dotenv()  \nimport google.generativeai as genai\nGEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\") # Bu kod, Gemini API’ye bağlanmayı sağlar.\n\ngenai.configure(api_key=\"AIzaSyCuw97w5GcuQcvMyiyVJfma2tKslsjOC-M\")\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n# resolve_gen_model() fonksiyonu mevcut modelleri kontrol ederek en güncel ve uygun Gemini sürümünü otomatik seçer.Bu sayede model değişse bile kodun bozulmadan çalışması sağlanır.\ndef resolve_gen_model(preferred=(\"gemini-1.5-flash-latest\", \n                                 \"gemini-1.5-flash-001\",\n                                 \"gemini-1.5-flash\",\n                                 \"gemini-1.5-pro-latest\",\n                                 \"gemini-1.5-pro\")) -> str:\n    try:\n        models = list(genai.list_models())\n        def supports(m):\n            methods = getattr(m, \"supported_generation_methods\", None) or []\n            methods = [x.lower() for x in methods]\n            return (\"generatecontent\" in \"\".join(methods)) or (\"generate_content\" in methods)\n        available = {m.name for m in models if supports(m)}\n        for cand in preferred:\n            if cand in available:\n                return cand\n            pref_with_prefix = f\"models/{cand}\" if not cand.startswith(\"models/\") else cand\n            if pref_with_prefix in available:\n                return pref_with_prefix\n        if available:\n            return sorted(available)[0]\n    except Exception:\n        pass\n    return \"gemini-1.5-flash-latest\"\n\nGEN_MODEL = resolve_gen_model()\nEMBED_MODEL = \"models/text-embedding-004\"  # bazı SDK'larda 'text-embedding-004' de çalışır\n\n# --------------------------------------------------------------\n## 2️⃣ Veri Seti: PURE Annotate Dataset\n# Bu aşamada, sistemin “gereksinim cümlelerini” öğrenmesi için Kaggle’daki Public Requirements PURE Dataset kullanılmıştır.\n# Dataset’te her satır, bir iş gereksinimini temsil eder (örneğin “System shall encrypt user data.”).\n# Bazı gereksinimler işlevseldir (Functional), bazıları ise kalite, güvenlik veya performans gibi konulara ait olup İşlevsel Olmayan (Non-Functional) olarak etiketlenmiştir.\n# --------------------------------------------------------------\nkaggle_path = \"/kaggle/input/public-requirementspure-dataset/Pure_Annotate_Dataset.csv\"\nlocal_path  = \"/mnt/data/Pure_Annotate_Dataset.csv\"\n\nif os.path.exists(kaggle_path):\n    df = pd.read_csv(kaggle_path, encoding=\"latin1\")\nelif os.path.exists(local_path):\n    df = pd.read_csv(local_path, encoding=\"latin1\")\nelse:\n    # Yedek (etiketsiz) örnekler: hepsini heuristikle etiketleyeceğiz.\n    df = pd.DataFrame({\n        \"sentence\": [\n            \"Bankacılık uygulamasında müşteri verisi gizliliği sağlanmalıdır ve tüm erişimler loglanmalıdır\",\n            \"Sistem yoğun saatte saniyede en az bin işlem sağlamalıdır ve gecikme iki yüz milisaniyeyi aşmamalıdır\",\n            \"Raporlama modülü PDF ve CSV dışa aktarımı desteklemeli, planlı rapor gönderimi sunmalıdır\",\n            \"Rol tabanlı erişim kontrolü uygulanmalı ve yetkiler merkezi olarak yönetilmelidir\",\n            \"Yedekleme günlük, otomatik ve şifreli yapılmalı; kurtarma testi aylık tekrarlanmalıdır\",\n            \"API için hız sınırlaması uygulanmalı ve hatalı girişte ayrıntı sızdırılmamalıdır\",\n            \"Kullanıcı arayüzü mobil uyumlu olmalı ve erişilebilirlik standartlarına uymalıdır\",\n            \"Ödeme altyapısı PCI-DSS ile uyumlu olmalı ve kart verisi tokenleştirilmelidir\",\n            \"Hata mesajları kullanıcı dostu olmalı; teknik ayrıntılar yalnızca loglarda yer almalıdır\",\n            \"Loglar en az bir yıl boyunca güvenli bir depoda saklanmalıdır\"\n        ]\n    })\n\n# Temizlik + NFR etiketi\ndf[\"sentence\"] = df[\"sentence\"].astype(str)\ndf_clean = df[df[\"sentence\"].str.split().str.len() >= 5].drop_duplicates(subset=\"sentence\").copy()\n\n# Eğer veri setinde NFR_boolean varsa onu kullan; yoksa heuristikten üret\nif \"NFR_boolean\" in df_clean.columns:\n    df_clean[\"nfr\"] = df_clean[\"NFR_boolean\"].fillna(0).astype(int)\nelse:\n    # Basit heuristik: kalite öznitelikleri => NFR\n    nfr_pat = r\"(güvenlik|şifreleme|kvkk|gdpr|pci[- ]?dss|iso\\s*27001|erişilebilirlik|uyumluluk|regülasyon|mevzuat|performans|gecikme|latency|throughput|yüksek erişilebilirlik|yedekleme|disaster|rto|rpo|log(la|)|izleme|availability|scal(e|)|ölçeklen|waf|rate[- ]?limit|sızma)\"\n    df_clean[\"nfr\"] = df_clean[\"sentence\"].str.lower().str.contains(nfr_pat).astype(int)\n\nsample_df = df_clean.sample(n=min(300, len(df_clean)), random_state=42)\nkb = sample_df[[\"sentence\", \"nfr\"]].reset_index(drop=True).rename(columns={\"sentence\": \"text\"})\nkb[\"id\"] = kb.index.astype(str)\nkb = kb[[\"id\", \"text\", \"nfr\"]]\nprint(f\"✅ Temizlenmiş veri boyutu: {kb.shape}\")\n\n# --------------------------------------------------------------\n## 3️⃣ Embedding (Gemini ile)\n# Her bir gereksinim cümlesi Gemini’nin embedding modeli ile sayısal vektöre dönüştürülür.\n# Bu vektörler, gereksinimler arasındaki benzerliği bulmakta kullanılır.\n# Örneğin:\n# “Sistem verileri şifrelemelidir.”\n# “Kullanıcı bilgileri güvenli şekilde saklanmalıdır.”\n# Bu iki cümle birbirine anlamca yakın olduğu için embedding uzayında birbirine yakın noktalar olarak temsil edilir.\n# --------------------------------------------------------------\ndef embed_texts(texts, batch_size=32):\n    vecs = []\n    for i in range(0, len(texts), batch_size):\n        for t in texts[i:i+batch_size]:\n            emb = genai.embed_content(model=EMBED_MODEL, content=t)\n            vecs.append(emb[\"embedding\"])\n    return vecs\n\n# --------------------------------------------------------------\n# 4️⃣ ChromaDB Knowledge Base\n# Bu bölümde, az önce oluşturulan gereksinim vektörleri ChromaDB adlı bir vektör veri tabanında saklanır.\n# ChromaDB, metinleri depolarken aynı zamanda benzerlik aramaları (semantic search) yapmamıza olanak tanır.\n# ChromaDB, RAG mimarisinin Retrieval kısmında kullanılır.\n# --------------------------------------------------------------\nimport chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.PersistentClient(path=\"./chroma_db\", settings=Settings(anonymized_telemetry=False)) # Bu, verileri diske kaydeder, böylece yeniden çalıştırıldığında bilgi tabanı kaybolmaz.\ntry:\n    collection = client.get_collection(\"requirements_kb\") #“requirements_kb” adında bir koleksiyon (bilgi tabanı) oluşturulur.\nexcept Exception:\n    collection = client.create_collection(name=\"requirements_kb\", metadata={\"hnsw:space\": \"cosine\"})\n\ntry:\n    collection.delete(where={})\nexcept Exception:\n    pass\n\nprint(\"🔎 Bilgi tabanı için embedding hesaplanıyor (Gemini)...\")\nkb_embeddings = embed_texts(kb[\"text\"].tolist(), batch_size=32)\n# Dataset’ten elde edilen embedding vektörleri bu koleksiyona eklenir.\ncollection.add(\n    ids=kb[\"id\"].tolist(),\n    documents=kb[\"text\"].tolist(),\n    embeddings=kb_embeddings,\n    metadatas=[{\"nfr\": int(v)} for v in kb[\"nfr\"].tolist()]\n)\n# Sonuçta elimizde, her gereksinim cümlesinin sayısal temsiline (embedding) göre aranabildiği bir bilgi tabanı olur.\n# Bu sayede kullanıcı yeni bir proje açıklaması yazdığında, sistem bu bilgi tabanından benzer gereksinimleri bulup bağlamsal olarak kullanabilir.\n# --------------------------------------------------------------\n## 5️⃣ BABOK Uyumlu Prompt\n# Burada modelin nasıl yanıt üreteceği “prompt” ile belirlenir.\n# Prompt içinde BABOK (Business Analysis Body of Knowledge) standartlarına uygun biçimde bir gereksinim çıktısı şablonu tanımlanır.\n# modelden şu alanları doldurması istenir:\n\n#Gereksinim Türü (Business / Stakeholder / Solution / Transition)\n#Gereksinim Doğası (Functional veya Non-Functional)\n#Gerekçe (Rationale)\n#Business Value\n#Stakeholders\n#Acceptance Criteria\n#MoSCoW önceliklendirmesi (Must/Should/Could/Won’t)\n#Kano modeli sınıfı\n#Cost of Delay yorumu\n\n# Bu yapının amacı, LLM’den sadece serbest metin almak yerine, iş analizi formatına uygun, yapısal ve ölçülebilir gereksinim çıktıları almak.\n# Ayrıca sistem, kullanıcının cümlesindeki ipuçlarına göre gereksinimi otomatik olarak Functional veya Non-Functional olarak sınıflandırır.\n# Bu sınıflandırma hem kelime temelli (heuristik) hem de embedding benzerliğiyle yapılır.\n# Yani sadece kelimelere değil, cümlenin anlamına da bakar.\n# --------------------------------------------------------------\nimport re\n\n# --- Functional / Non-Functional tetikleyicileri ---\nFN_TRIGGERS = r\"(oluştur|kaydet|göster|listele|arama|güncelle|sil|ihraç|dışa aktar|içe aktar|onayla|doğrula|entegr(e|a)|yönlendir|bildir|planla|kapat|aç|tanımla|başlat|bitir|işleme al|işlet)\"\nNF_TRIGGERS = r\"(güvenlik|şifreleme|mfa|kvkk|gdpr|pci[- ]?dss|iso\\s*27001|erişilebilirlik|uyumluluk|regülasyon|mevzuat|performans|gecikme|latency|throughput|qps|rps|ölçeklen|availability|yüksek erişilebilirlik|yedekleme|disaster|kurtarma|rto|rpo|log(la|)|izleme|audit|rate[- ]?limit|waf|sızma|hata mesajı|kullanılabilirlik|stabilite|güvenirlik|reliability)\"\n\n# --- Heuristik + komşu oyu ile F/NF sınıflandırma ---\n# Heuristik Analiz:\n# Anahtar kelimelerle (ör. performans, güvenlik, kaydet, sil) Functional / Non-Functional kararını verir.\n# Komşuluk Analizi:\n# Kullanıcı cümlesi embedding’e dönüştürülür ve ChromaDB’deki en yakın komşuların NFR ortalaması hesaplanır.\n\n#Birleştirme:\n#Eğer heuristik kararsızsa, embedding temelli komşuluk sonucu kullanılır.\ndef classify_fnf(user_query: str, top_k: int = 5) -> str:\n    text = (user_query or \"\").lower()\n\n    # 1) Heuristik kısa devre\n    if re.search(NF_TRIGGERS, text):\n        heuristic = 1\n    elif re.search(FN_TRIGGERS, text):\n        heuristic = 0\n    else:\n        heuristic = -1  # kararsız\n\n    # 2) Embedding komşuları üzerinden çoğunluk oyu (NFR ortalaması)\n    try:\n        q_emb = genai.embed_content(model=EMBED_MODEL, content=user_query)[\"embedding\"]\n        results = collection.query(query_embeddings=[q_emb], n_results=max(1, min(top_k, 10)))\n        metas = results.get(\"metadatas\", [[]])[0] if results else []\n        votes = [int(m.get(\"nfr\", 0)) for m in metas]\n        neighbor_score = (sum(votes) / len(votes)) if votes else 0.0\n    except Exception:\n        neighbor_score = 0.0\n\n    # 3) Birleştir: heuristik ağır basar; değilse komşular\n    if heuristic == 1:\n        return \"Non-Functional\"\n    if heuristic == 0:\n        return \"Functional\"\n    return \"Non-Functional\" if neighbor_score >= 0.5 else \"Functional\"\n\n# --- BABOK uyumlu çıktı üreten prompt ---\ndef generate_babok_prompt(user_query, retrieved_docs, fnf_label: str):\n    docs_text = \"\\n\".join([f\"- {doc}\" for doc in retrieved_docs])\n    prompt = f\"\"\"Kullanıcının proje açıklaması: \"{user_query}\"\n\nBenzer gereksinim örnekleri:\n{docs_text}\n\nBu proje açıklaması için varsayılan gereksinim doğası: **{fnf_label}**.\nÜreteceğin her gereksinimde bunu DOLDUR (Functional veya Non-Functional).\n\nBABOK (Business Analysis Body of Knowledge) standartlarına göre gereksinim önerileri üret.\nHer gereksinim için AŞAĞIDAKİ alanları eksiksiz doldur:\n\n────────────────────────────\n**Gereksinim Türü:** (Business / Stakeholder / Solution / Transition)\n**Gereksinim Doğası (F/NF):** (Functional veya Non-Functional)\n**Gereksinim:** ...\n**Rationale (Gerekçe):** ...\n**Business Value:** ...\n**Stakeholders (Etkilenen Paydaşlar):** ...\n**Acceptance Criteria:** ... (ölçülebilir ve test edilebilir)\nAyrıca her gereksinim için şunları da öner:\n- MoSCoW: Must/Should/Could/Won't (kısa neden)\n- Impact (1-5), Effort (1-5), Risk (1-5)\n- Kano sınıfı: Temel / Performans / Heyecan (1 cümle gerekçe)\n- Cost of Delay’e kısa yorum (varsa regülasyon/güvenlik vurgula)\n────────────────────────────\n\nYanıtı Türkçe olarak oluştur. Kısa, net ve ölçülebilir kabul kriterleri ver.\nÖncelikleri MoSCoW (Must/Should/Could/Won't) ile belirt.\n\"\"\"\n    return prompt\n# --------------------------------------------------------------\n## 6️⃣ Gereksinim Önceliklendirme Modülü\n# İş analistlerinin en zor görevlerinden biri: hangi gereksinimin öncelikli olduğunu belirlemektir.\n# Bu bölümde, sistem kullanıcıdan gelen gereksinimi analiz ederek RICE ve WSJF skorları hesaplar.\n# Kısaca:\n\n#RICE = (Reach × Impact × Confidence) / Effort\n#WSJF = (Business Value + Time Criticality + Risk Reduction) / Job Size\n#Kod, gereksinimdeki anahtar kelimelere göre etki, risk ve iş yükünü tahmin eder.\n\n#Örneğin:\n\n#Eğer metinde “güvenlik”, “şifreleme”, “regülasyon” gibi kelimeler varsa → Risk ve Etki yüksek atanır.\n\n#Performans veya ölçeklenebilirlik vurgusu varsa → Impact artar.\n\n#Bu sinyallerle otomatik skorlar hesaplanır.\n\n#Sonuç: Kullanıcı yalnızca kısa bir proje cümlesi yazsa bile, sistem arka planda onun önceliklendirilmiş gereksinim analizini çıkarır.\n# --------------------------------------------------------------\n\nKEYS = {\n    \"security\": r\"(güvenlik|mfa|şifreleme|pci[- ]?dss|gdpr|iso\\s*27001|yetki|rol|erişim|token|sızma|waf)\",\n    \"perf\": r\"(performans|gecikme|lat(ency)?|ölçeklen|throughput|qps|rps|benchmark)\",\n    \"compliance\": r\"(uyumluluk|regülasyon|mevzuat|kvkk|gdpr|sox|hipaa)\",\n    \"availability\": r\"(yedekleme|yüksek erişilebilirlik|ha|disaster|kurtarma|rto|rpo)\"\n}\n\ndef heuristic_signals(text: str): #Metindeki anahtar kelimelere göre risk ve etki puanı çıkarır.\n    t = text.lower()\n    sig = {\n        \"is_security\": 1 if re.search(KEYS[\"security\"], t) else 0,\n        \"is_perf\": 1 if re.search(KEYS[\"perf\"], t) else 0,\n        \"is_compliance\": 1 if re.search(KEYS[\"compliance\"], t) else 0,\n        \"is_availability\": 1 if re.search(KEYS[\"availability\"], t) else 0,\n    }\n    sig[\"risk_hint\"] = 5 if (sig[\"is_security\"] or sig[\"is_compliance\"]) else 3 if sig[\"is_availability\"] else 2\n    sig[\"impact_hint\"] = 4 if (sig[\"is_perf\"] or sig[\"is_security\"]) else 3\n    return sig\n\ndef score_rice(reach:int, impact:float, confidence:float, effort:float) -> float:\n    confidence = max(0.1, min(confidence, 1.0))\n    effort = max(0.1, effort)\n    return (reach * impact * confidence) / effort\n\ndef score_wsjf(business_value:int, time_criticality:int, risk_reduction:int, job_size:float) -> float:\n    cod = business_value + time_criticality + risk_reduction\n    job_size = max(0.1, job_size)\n    return cod / job_size\n\ndef enrich_with_priorities(req_text: str):\n    sig = heuristic_signals(req_text)\n    reach = 100 if sig[\"impact_hint\"] >= 4 else 50\n    impact = 2.0 if sig[\"impact_hint\"] >= 4 else 1.0\n    confidence = 0.7\n    effort = 3.0 if sig[\"is_security\"] else 2.0\n    rice = score_rice(reach, impact, confidence, effort)\n\n    business_value = 5 if sig[\"impact_hint\"] >= 4 else 3\n    time_criticality = sig[\"risk_hint\"]\n    risk_reduction = 4 if sig[\"is_security\"] or sig[\"is_compliance\"] else 2\n    job_size = 3.0 if sig[\"is_security\"] else 2.0\n    wsjf = score_wsjf(business_value, time_criticality, risk_reduction, job_size)\n\n    return {\"RICE\": round(rice, 2), \"WSJF\": round(wsjf, 2),\n            \"Risk\": sig[\"risk_hint\"], \"Impact\": sig[\"impact_hint\"]}\n\n# --------------------------------------------------------------\n## 7️⃣ RAG Pipeline\n# Bu aşama projenin beyni sayılabilir.\n# RAG mimarisi, iki aşamadan oluşur:\n\n# Retrieval (Bilgi Getirme):\n# Kullanıcının sorgusu embedding’e dönüştürülür ve ChromaDB içinde benzer gereksinimler aranır.\n# Böylece model, ilgili gerçek bilgilerle desteklenir.\n\n# Generation (İçerik Üretme):\n# Bulunan belgeler, modelin “hafızasına” verilerek daha isabetli ve bağlamlı bir yanıt üretilmesi sağlanır.\n\n# Sonuç olarak model hem veriye dayalı hem de yaratıcı bir şekilde yanıt üretir.\n# Bu yaklaşım, yalnızca dil modeline dayanan sistemlerden çok daha doğru, izlenebilir ve açıklanabilir sonuçlar verir.\n# --------------------------------------------------------------\ndef rag_response_babok(user_query, top_k=5):\n    if not user_query or not user_query.strip():\n        return \"⚠️ Lütfen bir proje açıklaması giriniz.\"\n\n    # Sorgu embedding\n    q_emb = genai.embed_content(model=EMBED_MODEL, content=user_query)[\"embedding\"]\n\n    # Chroma sorgu\n    results = collection.query(query_embeddings=[q_emb], n_results=max(1, min(top_k, 10)))\n    retrieved_docs = results.get(\"documents\", [[]])[0] if results else []\n    if not retrieved_docs:\n        retrieved_docs = [\"Benzer örnek bulunamadı. Genel şablona göre üret.\"]\n\n    # Functional / Non-Functional sınıflandır\n    fnf_label = classify_fnf(user_query, top_k=top_k)\n\n    # LLM üretim\n    prompt = generate_babok_prompt(user_query, retrieved_docs, fnf_label)\n    model = genai.GenerativeModel(GEN_MODEL)\n    response = model.generate_content(prompt)\n    text = response.text if getattr(response, \"text\", None) else \"⚠️ Modelden yanıt alınamadı.\"\n\n    # Öncelik skorları (mevcut modül)\n    prio = enrich_with_priorities(user_query)\n    extra = (\n        \"\\n\\n🧮 **Önerilen Önceliklendirme**\"\n        f\"\\n- RICE: {prio['RICE']}\"\n        f\"\\n- WSJF: {prio['WSJF']}\"\n        f\"\\n- Risk: {prio['Risk']}\"\n        f\"\\n- Impact: {prio['Impact']}\"\n        f\"\\n\\n🏷️ **Genel Gereksinim Doğası (F/NF) Tahmini:** {fnf_label}\"\n    )\n    return text + extra\n\n# --------------------------------------------------------------\n## 8️⃣ Gradio Arayüzü\n# İş analistinin veya proje yöneticisinin, teknik detaylara girmeden sadece bir metin yazarak gereksinim raporu almasını sağlamak.\n# Arayüzde kullanıcı bir proje açıklaması yazar, sistem de BABOK formatında yanıt döndürür.\n# --------------------------------------------------------------\ndef chatbot_interface(user_input):\n    if not user_input.strip():\n        return \"⚠️ Lütfen bir proje açıklaması giriniz.\"\n    return rag_response_babok(user_input)\n\ndemo = gr.Interface(\n    fn=chatbot_interface,\n    inputs=gr.Textbox(\n        lines=4,\n        placeholder=\"Proje açıklamasını giriniz (ör. 'Bankacılık uygulamasında müşteri verisi güvenliği ve işlem performansı').\",\n        label=\"💬 Proje Açıklaması\"\n    ),\n    outputs=gr.Markdown(label=\"📘 BABOK Uyumlu Gereksinim Önerileri\"),\n    title=\"Business Requirement Chatbot (BABOK + RAG)\",\n    description=\"PURE Dataset + BABOK Framework + Gemini RAG tabanlı iş analizi asistanı\",\n    theme=\"soft\",\n    allow_flagging=\"never\"\n)\n# Bu yapı sayesinde proje, tek satır kodla web üzerinde çalıştırılabilir hale gelir.\n# --------------------------------------------------------------\n# 9️⃣ Test: Kod sonunda örnek çıktı\n# --------------------------------------------------------------\nif __name__ == \"__main__\":\n    test_query = \"Günlük 5 milyon API çağrısını %99.9 başarı ile işleyebilmelidir.\"\n    print(\"🚀 TEST ÇALIŞTIRILIYOR...\")\n    print(f\"📝 Sorgu: {test_query}\\n\")\n    test_answer = rag_response_babok(test_query, top_k=5)\n    print(\"📘 Örnek Çıktı:\\n\")\n    print(test_answer)\n\n# Gradio arayüzünü başlatmak istersen:\n# demo.launch(share=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T13:26:55.071931Z","iopub.status.idle":"2025-10-23T13:26:55.072331Z","shell.execute_reply.started":"2025-10-23T13:26:55.072113Z","shell.execute_reply":"2025-10-23T13:26:55.072132Z"}},"outputs":[],"execution_count":null}]}